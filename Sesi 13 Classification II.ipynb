{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4a8686",
   "metadata": {},
   "source": [
    "# Hacktiv8-PTP Python For Data Science // S.13 // Classification - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea520867",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1dfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes adalah teknik klasifikasi statistik berdasarkan Bayes Theorem. Ini adalah salah satu supervised learning algorithms yang paling sederhana. Naive Bayes classifier adalah algoritme yang cepat, akurat, dan andal. Naive Bayes classifier memiliki akurasi dan kecepatan tinggi pada kumpulan data besar.\n",
    "\n",
    "#Naive Bayes classifier mengasumsikan bahwa efek fitur tertentu dalam kelas tidak bergantung pada fitur lainnya. Misalnya, pemohon pinjaman diloloskan atau tidak tergantung pada pendapatannya, pinjaman sebelumnya dan riwayat transaksi, usia, dan lokasi. Meskipun fitur ini saling bergantung, fitur ini masih dianggap terpisah. Asumsi ini menyederhanakan komputasi, dan itulah mengapa dianggap naive. Asumsi ini disebut class conditional independence.\n",
    "# P(h): the probability of hypothesis h being true (regardless of the data). This is known as the prior probability of h.\n",
    "# P(D): the probability of the data (regardless of the hypothesis). This is known as the prior probability.\n",
    "# P(h|D): the probability of hypothesis h given the data D. This is known as posterior probability.\n",
    "# P(D|h): the probability of data d given that the hypothesis h was true. This is known as posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd383c6e",
   "metadata": {},
   "source": [
    "## How Naive Bayes classifier works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15049718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mari kita pahami cara kerja Naive Bayes melalui sebuah contoh. Diberikan contoh kondisi cuaca dan keputusan bermain olah raga. Kita perlu menghitung kemungkinan bermain olahraga. Sekarang, kita perlu mengklasifikasikan apakah pemain akan bermain atau tidak, berdasarkan kondisi cuaca.\n",
    "\n",
    "#Naive Bayes classifier menghitung probabilitas suatu peristiwa dalam langkah-langkah berikut:\n",
    "# Step 1: Calculate the prior probability for given class labels\n",
    "# Step 2: Find Likelihood probability with each attribute for each class\n",
    "# Step 3: Put these value in Bayes Formula and calculate posterior probability.\n",
    "# Step 4: See which class has a higher probability, given the input belongs to the higher probability class.\n",
    "\n",
    "#Untuk menyederhanakan perhitungan probabilitas prior dan posterior kita dapat menggunakan dua tables frequency dan likelihood tables. Kedua tabel ini akan membantu kita menghitung probabilitas prior dan posterior. Frequency table berisi kemunculan label untuk semua fitur. Ada dua tabel kemungkinan. Likelihood Table 1 menunjukkan probabilitas sebelumnya dari label dan Likelihood Table 2 menunjukkan probabilitas posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39206d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sekarang misalkan kita ingin menghitung probabilitas bermain (Yes/No) saat cuaca mendung (Overcast)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ac1cb",
   "metadata": {},
   "source": [
    "#### Probability of playing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091088f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(Yes | Overcast) = P(Overcast | Yes) P(Yes) / P (Overcast)\n",
    "\n",
    "#Calculate Prior Probabilities:\n",
    "# P(Overcast) = 4/14 = 0.29\n",
    "# P(Yes)= 9/14 = 0.64\n",
    "\n",
    "#Calculate Posterior Probabilities:\n",
    "# P(Overcast |Yes) = 4/9 = 0.44\n",
    "\n",
    "#Put Prior and Posterior probabilities in equation\n",
    "# P (Yes | Overcast) = 0.44 * 0.64 / 0.29 = 0.98(Higher)\n",
    "\n",
    "#Similarly, you can calculate the probability of not playing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d6fd0",
   "metadata": {},
   "source": [
    "#### Probability of not playing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58677b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(No | Overcast) = P(Overcast | No) P(No) / P (Overcast)\n",
    "\n",
    "#Calculate Prior Probabilities:\n",
    "# P(Overcast) = 4/14 = 0.29\n",
    "# P(No)= 5/14 = 0.36\n",
    "\n",
    "#Calculate Posterior Probabilities:\n",
    "# P(Overcast |No) = 0/9 = 0\n",
    "\n",
    "#Put Prior and Posterior probabilities in equation\n",
    "# P (No | Overcast) = 0 * 0.36 / 0.29 = 0\n",
    "\n",
    "#Probabilitas kelas 'Yes' lebih tinggi. Jadi kita bisa menentukan disini jika cuaca mendung maka pemain akan melakukan olah raga.\n",
    "\n",
    "#Sekarang misalkan kita ingin menghitung probabilitas bermain saat cuaca mendung (Overcast), dan suhunya sedang (Mild)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e1ae0",
   "metadata": {},
   "source": [
    "#### Probability of playing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbde8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(Play= Yes | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play= Yes)P(Play=Yes)\n",
    "\n",
    "#P(Weather=Overcast, Temp=Mild | Play= Yes)= P(Overcast |Yes) P(Mild |Yes)\n",
    "\n",
    "#Calculate Prior Probabilities: P(Yes)= 9/14 = 0.64\n",
    "\n",
    "#Calculate Posterior Probabilities: P(Overcast |Yes) = 4/9 = 0.44 P(Mild |Yes) = 4/9 = 0.44\n",
    "\n",
    "#Put Posterior probabilities in equation (2) P(Weather=Overcast, Temp=Mild | Play= Yes) = 0.44 * 0.44 = 0.1936(Higher)\n",
    "\n",
    "#Put Prior and Posterior probabilities in equation (1) P(Play= Yes | Weather=Overcast, Temp=Mild) = 0.1936*0.64 = 0.124\n",
    "\n",
    "#Similarly, you can calculate the probability of not playing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88709c",
   "metadata": {},
   "source": [
    "#### Probability of not playing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75893125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(Play= No | Weather=Overcast, Temp=Mild) = P(Weather=Overcast, Temp=Mild | Play= No)P(Play=No)\n",
    "\n",
    "#P(Weather=Overcast, Temp=Mild | Play= No)= P(Weather=Overcast |Play=No) P(Temp=Mild | Play=No)\n",
    "\n",
    "#Calculate Prior Probabilities: P(No)= 5/14 = 0.36\n",
    "\n",
    "#Calculate Posterior Probabilities: P(Weather=Overcast |Play=No) = 0/9 = 0 P(Temp=Mild | Play=No)=2/5=0.4\n",
    "\n",
    "#Put posterior probabilities in equation (4) P(Weather=Overcast, Temp=Mild | Play= No) = 0 * 0.4= 0\n",
    "\n",
    "#Put prior and posterior probabilities in equation (3) P(Play= No | Weather=Overcast, Temp=Mild) = 0*0.36=0\n",
    "\n",
    "#Probabilitas kelas 'Yes' lebih tinggi. Jadi bisa dibilang disini kalau cuaca mendung dan suhunya sedang maka pemain akan main olahraga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf92c2",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier Building in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a45d1",
   "metadata": {},
   "source": [
    "#### Defining Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8534ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dalam contoh ini, kita dapat menggunakan kumpulan data dummy dengan tiga kolom: weather, temperature, dan play. Dua yang pertama adalah features(weather, temperature) dan yang lainnya adalah label.\n",
    "\n",
    "# Assigning features and label variables\n",
    "\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny', 'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c4906e",
   "metadata": {},
   "source": [
    "#### Encoding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8084314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Pertama, kita perlu mengubah string menjadi angka, misalnya: 'Overcast', 'Rainy', 'Sunny' sebagai 0, 1, 2. Ini dikenal sebagai label encoding. Scikit-learn menyediakan pustaka LabelEncoder untuk mengenkode label dengan nilai.\n",
    "\n",
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded=le.fit_transform(weather)\n",
    "\n",
    "print(weather_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525d5f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp: [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
      "Play: [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Converting string labels into numbers\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "label=le.fit_transform(play)\n",
    "\n",
    "print(\"Temp:\",temp_encoded)\n",
    "print(\"Play:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77082ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1),\n",
       " (2, 1),\n",
       " (0, 1),\n",
       " (1, 2),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (2, 0),\n",
       " (1, 2),\n",
       " (2, 2),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (1, 2)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinig weather and temp into single listof tuples\n",
    "\n",
    "features=list(zip(weather_encoded,temp_encoded))\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f04e24cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [1]\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features,label)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "print(\"Predicted Value:\", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95024aab",
   "metadata": {},
   "source": [
    "## Naive Bayes with Multiple Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae39fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampai saat ini kita  telah mempelajari klasifikasi Naive Bayes dengan label biner. Sekarang kita akan belajar tentang multiple class classification di Naive Bayes. Yang dikenal sebagai multinomial Naive Bayes classification. Misalnya, jika kita ingin mengklasifikasikan artikel berita tentang teknologi, hiburan, politik, atau olahraga.\n",
    "#Pada bagian pembuatan model, kita dapat menggunakan dataset wine yang merupakan multi-class classification yang sangat terkenal. Kumpulan data ini adalah hasil dari analisis kimiawi anggur yang ditanam di wilayah yang sama di Italia tetapi berasal dari tiga kultivar berbeda.\n",
    "#Set data terdiri dari 13 fitur (alcohol, malic_acid, ash, alcalinity_of_ash, magnesium, total_phenols, flavanoids, nonflavanoid_phenols, proanthocyanins, color_intensity, hue, od280/od315_of_diluted_wines, proline) dan type of wine cultivar. Data ini memiliki tiga jenis anggur Class_0, Class_1, dan Class_3. Di sini kita  dapat membuat model untuk mengklasifikasikan jenis anggur.\n",
    "#Dataset tersedia di pustaka scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9855e5",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30010d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first load the required wine dataset from scikit-learn datasets.\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605be2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Labels:  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# print the names of the 13 features\n",
    "print(\"Features: \", wine.feature_names)\n",
    "\n",
    "# print the label type of wine(class_0, class_1, class_2)\n",
    "print(\"Labels: \", wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3caca064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data(feature)shape\n",
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b43051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n"
     ]
    }
   ],
   "source": [
    "# print the wine data features (top 5 records)\n",
    "print(wine.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cec405fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# print the wine labels (0:Class_0, 1:class_2, 2:class_2)\n",
    "print(wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2ea729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3,random_state=109) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e70f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e290d6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3385a",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree adalah flowchart-like tree structure di mana internal node mewakili feature(atau attribute), branch mewakili decision rule, dan setiap leaf node mewakili outcome. Node paling atas dalam pohon keputusan dikenal sebagai root node. Root node belajar untuk mempartisi berdasarkan nilai atribut. Root node mempartisi pohon secara rekursif memanggil partisi rekursif. Flowchart-like structure ini membantu kita dalam pengambilan keputusan. Visualisasinya seperti diagram flowchart yang dengan mudah meniru pemikiran tingkat manusia. Itulah mengapa decision trees mudah dipahami dan diinterpretasikan.\n",
    "\n",
    "#How does the Decision Tree algorithm work?\n",
    "#Ide dasar di balik decision tree algorithm adalah sebagai berikut:\n",
    "# Select the best attribute using Attribute Selection Measures(ASM) to split the records.\n",
    "# Make that attribute a decision node and breaks the dataset into smaller subsets.\n",
    "# Starts tree building by repeating this process recursively for each child until one of the condition will match:\n",
    "  # All the tuples belong to the same attribute value.\n",
    "  # There are no more remaining attributes.\n",
    "  # There are no more instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0166b6",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier Building in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba7a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80e4a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "# load dataset\n",
    "pima = pd.read_csv(\"https://raw.githubusercontent.com/ardhiraka/PFDS_sources/master/diabetes.csv\", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c99c5be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>Glucose</td>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>Insulin</td>\n",
       "      <td>BMI</td>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>Age</td>\n",
       "      <td>Outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pregnant  glucose             bp           skin  insulin   bmi  \\\n",
       "0  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI   \n",
       "1            6      148             72             35        0  33.6   \n",
       "2            1       85             66             29        0  26.6   \n",
       "3            8      183             64              0        0  23.3   \n",
       "4            1       89             66             23       94  28.1   \n",
       "\n",
       "                   pedigree  age    label  \n",
       "0  DiabetesPedigreeFunction  Age  Outcome  \n",
       "1                     0.627   50        1  \n",
       "2                     0.351   31        0  \n",
       "3                     0.672   32        1  \n",
       "4                     0.167   21        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b323f",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df9fa5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 769 entries, 0 to 768\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   pregnant  769 non-null    object\n",
      " 1   glucose   769 non-null    object\n",
      " 2   bp        769 non-null    object\n",
      " 3   skin      769 non-null    object\n",
      " 4   insulin   769 non-null    object\n",
      " 5   bmi       769 non-null    object\n",
      " 6   pedigree  769 non-null    object\n",
      " 7   age       769 non-null    object\n",
      " 8   label     769 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 54.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Di sini, kita perlu membagi kolom yang diberikan menjadi dua jenis variabel dependen (atau variabel target) dan variabel independen (atau variabel fitur).\n",
    "\n",
    "pima.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc6eb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numer = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree', 'label']\n",
    "\n",
    "for col in numer: # coerce for missing values\n",
    "    pima[col] = pd.to_numeric(pima[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21049a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "423f6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "382f3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc86288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f017345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6926406926406926\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596f3ef",
   "metadata": {},
   "source": [
    "### Visualizing Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdcafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kita bisa menggunakan fungsi export_graphviz Scikit-learn untuk menampilkan tree dalam notebook Jupyter. Untuk plotting tree, kita juga perlu menginstal graphviz dan pydotplus.\n",
    "# pip install graphviz\n",
    "# pip install pydotplus\n",
    "\n",
    "#Fungsi export_graphviz mengubah decision tree classifier menjadi dot file dan pydotplus mengonversi file dot ini ke png atau bentuk yang dapat ditampilkan di Jupyter.\n",
    "\n",
    "#!conda install python-graphviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7876ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, \n",
    " out_file=dot_data, \n",
    " class_names=['0','1'], # the target names.\n",
    " feature_names=feature_cols, # the feature names.\n",
    " filled=True, # Whether to fill in the boxes with colours.\n",
    " rounded=True, # Whether to round the corners of the boxes.\n",
    " special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee94387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing Decision Tree Performance\n",
    "# criterion : optional (default=”gini”) or Choose attribute selection measure: This parameter allows us to use the different-different attribute selection measure. Supported criteria are “gini” for the Gini index and “entropy” for the information gain.\n",
    "# splitter : string, optional (default=”best”) or Split Strategy: This parameter allows us to choose the split strategy. Supported strategies are “best” to choose the best split and “random” to choose the best random split.\n",
    "# max_depth : int or None, optional (default=None) or Maximum Depth of a Tree: The maximum depth of the tree. If None, then nodes are expanded until all the leaves contain less than min_samples_split samples. The higher value of maximum depth causes overfitting, and a lower value causes underfitting (Source).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dalam Scikit-learn, pengoptimalan decision tree classifier dilakukan hanya dengan pre-pruning. Maximum depth pohon dapat digunakan sebagai variabel kontrol untuk pre-pruning. Dalam contoh berikut, kita dapat memplot decision tree pada data yang sama dengan max_depth = 3. Selain parameter pre-pruning, kita  juga dapat mencoba ukuran pemilihan atribut lain seperti entropy.\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, \n",
    " out_file=dot_data, \n",
    " class_names=['0','1'], # the target names.\n",
    " feature_names=feature_cols, # the feature names.\n",
    " filled=True, # Whether to fill in the boxes with colours.\n",
    " rounded=True, # Whether to round the corners of the boxes.\n",
    " special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7b5bd",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest secara teknis adalah ensemble method (berdasarkan pendekatan divide-and-conquer) dari decision trees yang dihasilkan pada dataset yang dipisahkan secara acak. Kumpulan decision tree classifiers ini juga dikenal sebagai forest. Decision trees individu dihasilkan menggunakan indikator pemilihan atribut seperti information gain, gain ratio, dan Gini index untuk setiap atribut. Setiap pohon bergantung pada sampel acak yang independen. Dalam masalah klasifikasi, setiap pohon memilih dan kelas paling populer dipilih sebagai hasil akhir. Dalam kasus regresi, rata-rata dari semua keluaran pohon dianggap sebagai hasil akhir. Ini lebih sederhana dan lebih kuat dibandingkan dengan algoritma klasifikasi non-linier lainnya.\n",
    "\n",
    "#How does the algorithm work?\n",
    "#Random forest bekerja dalam 4 tahap:\n",
    "# Select random samples from a given dataset.\n",
    "# Construct a decision tree for each sample and get a prediction result from each decision tree.\n",
    "# Perform a vote for each predicted result.\n",
    "# Select the prediction result with the most votes as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385575ea",
   "metadata": {},
   "source": [
    "### Finding important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994efc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forests juga menawarkan indikator feature selection yang baik. Scikit-learn menyediakan variabel tambahan dengan model tersebut, yang menunjukkan importance relatif atau kontribusi setiap fitur dalam prediksi. Secara otomatis menghitung skor relevansi setiap fitur dalam fase training . Kemudian menurunkan relevansi sehingga jumlah semua skor adalah 1.\n",
    "\n",
    "#Skor ini akan membantu kita memilih fitur yang paling penting dan menghapus fitur yang paling tidak penting untuk pembuatan model.\n",
    "\n",
    "#Random forests menggunakan gini importance atau mean decrease in impurity (MDI) untuk menghitung tingkat importance setiap fitur. Gini importance juga dikenal sebagai total decrease dalam node impurity. Ini adalah seberapa besar kecocokan atau akurasi model menurun saat kita menghapus variabel. Semakin besar penurunannya, semakin signifikan variabel tersebut. Di sini, mean decrease adalah parameter signifikan untuk pemilihan variabel. Gini index dapat menggambarkan kekuatan penjelas variabel secara keseluruhan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7071df",
   "metadata": {},
   "source": [
    "### Random Forests vs Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03605cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forests adalah kumpulan dari beberapa decision trees.\n",
    "\n",
    "#Deep decision trees mungkin mengalami overfitting, tetapi random forests mencegah overfitting dengan membuat trees pada random subsets.\n",
    "\n",
    "#Decision trees secara komputasi lebih cepat.\n",
    "\n",
    "#Random forests sulit untuk diinterpretasikan, sedangkan decision tree mudah diinterpretasikan dan dapat diubah menjadi rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7253d2f",
   "metadata": {},
   "source": [
    "### Building a Classifier using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93183d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kita akan membuat model pada kumpulan data iris flower, yang merupakan kumpulan klasifikasi yang sangat terkenal. Terdiri dari sepal length, sepal width, petal length, petal width, dan jenis bunga. Ada tiga spesies atau kelas: setosa, versicolor, dan virginia. Kita akan membangun model untuk mengklasifikasikan jenis bunga. Dataset tersedia di pustaka scikit-learn atau kita dapat mengunduhnya dari Repositori Machine Learning UCI.\n",
    "\n",
    "#Mulailah dengan mengimpor pustaka kumpulan data dari scikit-learn, dan muat kumpulan data iris dengan load_iris().\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets \n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26825a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "#Kita dapat mencetak target dan feature , untuk memastikan kita memiliki dataset yang tepat, seperti:\n",
    "\n",
    "# print the label species(setosa, versicolor,virginica)\n",
    "print(iris.target_names) \n",
    "\n",
    "# print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5071e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#Ada baiknya untuk selalu menjelajahi data kita sedikit, sehingga kita tahu apa yang sedang kita kerjakan. Di sini, kita dapat melihat lima baris pertama kumpulan data dicetak, serta variabel target untuk seluruh kumpulan data.\n",
    "\n",
    "# print the iris data (top 5 records)\n",
    "print(iris.data[0:5]) \n",
    "\n",
    "# print the iris labels (0:setosa, 1:versicolor, 2:virginica)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebae3386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Di sini, kita dapat membuat DataFrame dari dataset iris dengan cara berikut.\n",
    "\n",
    "# Creating a DataFrame of given iris dataset.\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.DataFrame({    \n",
    "    'sepal length':iris.data[:,0],    \n",
    "    'sepal width':iris.data[:,1],    \n",
    "    'petal length':iris.data[:,2],    \n",
    "    'petal width':iris.data[:,3],    \n",
    "    'species':iris.target \n",
    "}) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aca3b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pertama, kita pisahkan kolom menjadi variabel dependen dan independen (atau features dan labels). Kemudian kita membagi variabel tersebut menjadi training dan test set.\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=data['species']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1046010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setelah dipisahkan, kita akan melatih model pada set training dan melakukan prediksi pada set test.\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    " \n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train) \n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c383f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "#etelah training, periksa accuracy menggunakan nilai actual dan predicted.\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa0c5052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kita juga dapat membuat prediksi untuk satu item, misalnya:\n",
    "# sepal length = 3\n",
    "# sepal width = 5\n",
    "# petal length = 4\n",
    "# petal width = 2\n",
    "#Sekarang kita  bisa memprediksi jenis bunganya.\n",
    "\n",
    "clf.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27161087",
   "metadata": {},
   "source": [
    "### Finding Important Features in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76016541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Di sini, kita dapat menemukan fitur penting atau memilih fitur dalam dataset IRIS. Dalam scikit-learn, kita dapat melakukan tugas ini dalam langkah-langkah berikut:\n",
    "# First, you need to create a random forests model.\n",
    "# Second, use the feature importance variable to see feature importance scores.\n",
    "# Third, visualize these scores using the seaborn library.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d482c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=None, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfe7640c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal length (cm)    0.483954\n",
       "petal width (cm)     0.385978\n",
       "sepal length (cm)    0.105252\n",
       "sepal width (cm)     0.024815\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False) \n",
    "\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3ee2d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Kita juga dapat memvisualisasikan feature importance. Visualisasi mudah dipahami dan diinterpretasikan.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c94f6",
   "metadata": {},
   "source": [
    "### Generating the Model on Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94237afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Di sini, kita dapat menghapus fitur \"sepal width\" karena tingkat kepentingannya sangat rendah, dan memilih 3 fitur lainnya.\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into features and labels\n",
    "X=data[['petal length', 'petal width','sepal length']]\n",
    "y=data['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87ed5854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "#Setelah dipisah, kita akan membuat model pada training set features yang dipilih, melakukan prediksi pada test set features yang dipilih, dan membandingkan nilai aktual dan nilai prediksi.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100) \n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train) \n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test) \n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fe8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kita dapat melihat bahwa setelah menghapus fitur yang paling tidak penting (sepal length), keakuratannya meningkat. Ini karena kita  menghapus data dan noise yang menyesatkan, sehingga meningkatkan akurasi. Jumlah fitur yang lebih sedikit juga mengurangi training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151ed23",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526db7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Secara umum, Support Vector Machines dianggap sebagai classification approach, tetapi dapat digunakan di kedua jenis masalah klasifikasi dan regresi. SVM dapat dengan mudah menangani beberapa variabel kontinu dan kategorikal. SVM membangun hyperplane  dalam multidimensional space untuk memisahkan kelas yang berbeda. SVM menghasilkan hyperplane optimal secara berulang, yang digunakan untuk meminimalkan kesalahan. Ide inti dari SVM adalah menemukan maximum marginal hyperplane(MMH) yang paling baik membagi dataset menjadi beberapa kelas.\n",
    "\n",
    "#Support Vectors\n",
    "#Support vectors adalah data points, yang paling dekat dengan hyperplane. Titik-titik ini akan menentukan garis pemisah dengan lebih baik dengan menghitung margin.\n",
    "\n",
    "#Hyperplane\n",
    "#Hyperplane adalah decision plane yang memisahkan antara sekumpulan objek yang memiliki kelas yang berbeda.\n",
    "\n",
    "#Margin\n",
    "#Margin adalah celah antara dua garis pada poin kelas terdekat. Margin dihitung sebagai jarak tegak lurus dari garis untuk mendukung vektor atau titik terdekat. Jika margin lebih besar di antara kelas, maka itu dianggap sebagai margin yang baik, margin yang lebih kecil adalah margin yang buruk.\n",
    "\n",
    "#How does SVM work?\n",
    "#Tujuan utamanya adalah untuk memisahkan kumpulan data yang diberikan dengan cara terbaik. Jarak antara salah satu titik terdekat dikenal sebagai margin. Tujuannya adalah untuk memilih hyperplane dengan kemungkinan margin maksimum antara support vectors dalam dataset yang diberikan. SVM mencari hyperplane marginal maksimum dalam langkah-langkah berikut:\n",
    "# Generate hyperplanes which segregates the classes in the best way. Left-hand side figure showing three hyperplanes black, blue and orange. Here, the blue and orange have higher classification error, but the black is separating the two classes correctly.\n",
    "# Select the right hyperplane with the maximum segregation from the either nearest data points as shown in the right-hand side figure.\n",
    "\n",
    "#Dealing with non-linear and inseparable planes\n",
    "#Beberapa masalah tidak dapat diselesaikan menggunakan linear hyperplane, seperti yang ditunjukkan pada gambar di bawah ini (sisi kiri).\n",
    "#Dalam situasi seperti itu, SVM menggunakan kernel untuk mengubah input space ke ruang dimensi yang lebih tinggi seperti yang ditunjukkan di sebelah kanan. Titik data diplot pada sumbu x dan sumbu z (Z adalah jumlah kuadrat dari x dan y: z=x^2=y^2). Sekarang kita dapat dengan mudah memisahkan titik-titik ini menggunakan pemisahan linier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fdde3",
   "metadata": {},
   "source": [
    "## SVM Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritma SVM diimplementasikan dalam praktiknya menggunakan kernel. Kernel mengubah input data space menjadi bentuk yang diperlukan. SVM menggunakan teknik yang disebut kernel. Di sini, kernel mengambil low-dimensional input space dan mengubahnya menjadi ruang berdimensi lebih tinggi. Dengan kata lain, kita dapat mengatakan bahwa SVM mengubah nonseparable problem menjadi separable problems dengan menambahkan lebih banyak dimensi padanya. SVM paling berguna dalam masalah pemisahan non-linier. Kernel membantu kita membuat pengklasifikasi yang lebih akurat.\n",
    "# Linear Kernel linear kernel dapat digunakan sebagai dot product pada dua pengamatan yang diberikan. Hasil perkalian antara dua vektor adalah hasil perkalian setiap pasang nilai masukan.\n",
    "\n",
    "K(x, xi) = sum(x * xi)\n",
    "\n",
    "# Polynomial Kernel Kernel polinomial adalah bentuk kernel linier yang lebih umum. Kernel polinomial dapat membedakan ruang masukan lengkung atau nonlinier.\n",
    "\n",
    "K(x,xi) = 1 + sum(x * xi)^d\n",
    "\n",
    "#Dimana d adalah derajat polinomial. d = 1 mirip dengan linear transformation. Degree perlu ditentukan secara manual dalam learning algorithm.\n",
    "\n",
    "# Radial Basis Function Kernel Radial basis function kernel adalah fungsi kernel populer yang biasa digunakan dalam support vector machine classification. RBF dapat memetakan ruang masukan dalam ruang dimensi tak terhingga.\n",
    "\n",
    "K(x,xi) = exp(-gamma * sum((x – xi^2))\n",
    "\n",
    "#Di sini gamma adalah parameter, yang berkisar dari 0 sampai 1. Nilai gamma yang lebih tinggi akan sangat cocok dengan training dataset, yang menyebabkan over-fitting. Gamma = 0.1 dianggap sebagai nilai default yang baik. Nilai gamma perlu ditentukan secara manual dalam learning algorithm.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b03d2",
   "metadata": {},
   "source": [
    "### Classifier Building in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampai saat ini, kita telah mempelajari tentang latar belakang teori SVM. Sekarang kita akan belajar tentang implementasinya dengan Python menggunakan scikit-learn.\n",
    "\n",
    "#Dalam membuat model, kita dapat menggunakan cancer dataset, yang merupakan multi-class classification problem yang sangat terkenal. Dataset ini dihitung dari gambar digital dari fine needle aspirate (FNA) dari massa payudara. Mereka menggambarkan karakteristik inti sel yang ada dalam gambar.\n",
    "\n",
    "#Dataset terdiri dari 30 fitur (mean radius, mean texture, mean perimeter, mean area, mean smoothness, mean compactness, mean concavity, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst radius, worst texture, worst perimeter, worst area, worst smoothness, worst compactness, worst concavity, worst concave points, worst symmetry, and worst fractal dimension) dan target (jenis kanker).\n",
    "\n",
    "#Data ini memiliki dua jenis kelas kanker: malignant (berbahaya) dan benign(tidak berbahaya). Di sini, kita  dapat membuat model untuk mengelompokkan jenis kanker. Dataset tersedia di pustaka scikit-learn atau kita juga dapat mengunduhnya dari UCI Machine Learning Library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ee4d3",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ef470d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mari muat dulu kumpulan data yang diperlukan yang akan kita gunakan.\n",
    "\n",
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets \n",
    "\n",
    "#Load dataset\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6a452",
   "metadata": {},
   "source": [
    "#### Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4994d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Labels:  ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "#Setelah kita memuat set data, kita  mungkin ingin tahu lebih banyak tentangnya. Kita dapat memeriksa fitur dan nama target.\n",
    "\n",
    "# print the names of the 13 features\n",
    "print(\"Features: \", cancer.feature_names) \n",
    "\n",
    "# print the label type of cancer('malignant' 'benign')\n",
    "print(\"Labels: \", cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e507debf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mari kita jelajahi lebih banyak lagi. Kita juga dapat memeriksa bentuk kumpulan data menggunakan shape.\n",
    "\n",
    "# print data(feature)shape\n",
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "978bef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      "  1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      "  6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      "  1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      "  4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 1.326e+03 8.474e-02 7.864e-02 8.690e-02\n",
      "  7.017e-02 1.812e-01 5.667e-02 5.435e-01 7.339e-01 3.398e+00 7.408e+01\n",
      "  5.225e-03 1.308e-02 1.860e-02 1.340e-02 1.389e-02 3.532e-03 2.499e+01\n",
      "  2.341e+01 1.588e+02 1.956e+03 1.238e-01 1.866e-01 2.416e-01 1.860e-01\n",
      "  2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 1.203e+03 1.096e-01 1.599e-01 1.974e-01\n",
      "  1.279e-01 2.069e-01 5.999e-02 7.456e-01 7.869e-01 4.585e+00 9.403e+01\n",
      "  6.150e-03 4.006e-02 3.832e-02 2.058e-02 2.250e-02 4.571e-03 2.357e+01\n",
      "  2.553e+01 1.525e+02 1.709e+03 1.444e-01 4.245e-01 4.504e-01 2.430e-01\n",
      "  3.613e-01 8.758e-02]\n",
      " [1.142e+01 2.038e+01 7.758e+01 3.861e+02 1.425e-01 2.839e-01 2.414e-01\n",
      "  1.052e-01 2.597e-01 9.744e-02 4.956e-01 1.156e+00 3.445e+00 2.723e+01\n",
      "  9.110e-03 7.458e-02 5.661e-02 1.867e-02 5.963e-02 9.208e-03 1.491e+01\n",
      "  2.650e+01 9.887e+01 5.677e+02 2.098e-01 8.663e-01 6.869e-01 2.575e-01\n",
      "  6.638e-01 1.730e-01]\n",
      " [2.029e+01 1.434e+01 1.351e+02 1.297e+03 1.003e-01 1.328e-01 1.980e-01\n",
      "  1.043e-01 1.809e-01 5.883e-02 7.572e-01 7.813e-01 5.438e+00 9.444e+01\n",
      "  1.149e-02 2.461e-02 5.688e-02 1.885e-02 1.756e-02 5.115e-03 2.254e+01\n",
      "  1.667e+01 1.522e+02 1.575e+03 1.374e-01 2.050e-01 4.000e-01 1.625e-01\n",
      "  2.364e-01 7.678e-02]]\n"
     ]
    }
   ],
   "source": [
    "#Mari kita periksa 5 record teratas dari set fitur.\n",
    "\n",
    "# print the cancer data features (top 5 records)\n",
    "print(cancer.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d08fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Mari kita lihat set target.\n",
    "\n",
    "# print the cancer labels (0:malignant, 1:benign)\n",
    "print(cancer.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fd48b",
   "metadata": {},
   "source": [
    "#### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca9083db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Untuk memahami performa model, membagi set data menjadi training set dan test set adalah strategi yang baik.\n",
    "\n",
    "#Pisahkan kumpulan data dengan menggunakan fungsi train_test_split(). Kita harus meneruskan 3 parameter features, target, and test_set size. Selain itu, kita dapat menggunakan random_state untuk memilih record secara acak.\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,random_state=109) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc50d28",
   "metadata": {},
   "source": [
    "#### Generating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65ef83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mari kita membangun support vector machine model. Pertama, impor modul SVM dan buat objek support vector classifier dengan meneruskan argumen kernel sebagai kernel linier dalam fungsi SVC().\n",
    "\n",
    "#Kemudian, training model kita di train set menggunakanfit() dan lakukan prediksi pada set test menggunakan predict().\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm \n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4e6ce",
   "metadata": {},
   "source": [
    "#### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2b4a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "#Mari kita perkirakan seberapa akurat pengklasifikasi atau model dapat memprediksi kanker payudara pasien.\n",
    "\n",
    "#Akurasi dapat dihitung dengan membandingkan nilai set test aktual dan nilai prediksi.\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics \n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "472821f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9811320754716981\n",
      "Recall: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "#Kita  mendapat tingkat klasifikasi 96.49%, dianggap sebagai akurasi yang sangat baik.\n",
    "\n",
    "#Untuk evaluasi lebih lanjut, kita juga dapat memeriksa precision dan recall model.\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred)) \n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kita mendapat precision 98% dan recall 96%, yang dianggap sebagai nilai yang sangat baik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3944bfbc",
   "metadata": {},
   "source": [
    "## Exercise: Multiple Algorithm on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "637b5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9bfc87dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/ardhiraka/PFDS_sources/master/Final_Dataset/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efc959e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>600.00000</td>\n",
       "      <td>564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5403.459283</td>\n",
       "      <td>1621.245798</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>342.00000</td>\n",
       "      <td>0.842199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6109.041673</td>\n",
       "      <td>2926.248369</td>\n",
       "      <td>85.587325</td>\n",
       "      <td>65.12041</td>\n",
       "      <td>0.364878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2877.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3812.500000</td>\n",
       "      <td>1188.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5795.000000</td>\n",
       "      <td>2297.250000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       614.000000         614.000000  592.000000         600.00000   \n",
       "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
       "std        6109.041673        2926.248369   85.587325          65.12041   \n",
       "min         150.000000           0.000000    9.000000          12.00000   \n",
       "25%        2877.500000           0.000000  100.000000         360.00000   \n",
       "50%        3812.500000        1188.500000  128.000000         360.00000   \n",
       "75%        5795.000000        2297.250000  168.000000         360.00000   \n",
       "max       81000.000000       41667.000000  700.000000         480.00000   \n",
       "\n",
       "       Credit_History  \n",
       "count      564.000000  \n",
       "mean         0.842199  \n",
       "std          0.364878  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6955d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed        32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data:\")\n",
    "print(train.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3d5ca71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount            0\n",
       "Loan_Amount_Term      0\n",
       "Credit_History        0\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.fillna(train.mean(),inplace=True) \n",
    "train.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf161884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Gender.fillna(train.Gender.mode()[0],inplace=True)\n",
    "train.Married.fillna(train.Married.mode()[0],inplace=True)\n",
    "train.Dependents.fillna(train.Dependents.mode()[0],inplace=True) \n",
    "train.Self_Employed.fillna(train.Self_Employed.mode()[0],inplace=True)  \n",
    "train.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73e54cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Loan_Amount_Term=np.log(train.Loan_Amount_Term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae8fecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop('Loan_Status',1)\n",
    "y=train.Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee163043",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(X)\n",
    "train=pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bddb785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Loan_ID_LP001002</th>\n",
       "      <th>Loan_ID_LP001003</th>\n",
       "      <th>Loan_ID_LP001005</th>\n",
       "      <th>Loan_ID_LP001006</th>\n",
       "      <th>Loan_ID_LP001008</th>\n",
       "      <th>...</th>\n",
       "      <th>Dependents_1</th>\n",
       "      <th>Dependents_2</th>\n",
       "      <th>Dependents_3+</th>\n",
       "      <th>Education_Graduate</th>\n",
       "      <th>Education_Not Graduate</th>\n",
       "      <th>Self_Employed_No</th>\n",
       "      <th>Self_Employed_Yes</th>\n",
       "      <th>Property_Area_Rural</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>5.886104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>5.886104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>5.886104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.886104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>5.886104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0  146.412162          5.886104   \n",
       "1             4583             1508.0  128.000000          5.886104   \n",
       "2             3000                0.0   66.000000          5.886104   \n",
       "3             2583             2358.0  120.000000          5.886104   \n",
       "4             6000                0.0  141.000000          5.886104   \n",
       "\n",
       "   Credit_History  Loan_ID_LP001002  Loan_ID_LP001003  Loan_ID_LP001005  \\\n",
       "0             1.0                 1                 0                 0   \n",
       "1             1.0                 0                 1                 0   \n",
       "2             1.0                 0                 0                 1   \n",
       "3             1.0                 0                 0                 0   \n",
       "4             1.0                 0                 0                 0   \n",
       "\n",
       "   Loan_ID_LP001006  Loan_ID_LP001008  ...  Dependents_1  Dependents_2  \\\n",
       "0                 0                 0  ...             0             0   \n",
       "1                 0                 0  ...             1             0   \n",
       "2                 0                 0  ...             0             0   \n",
       "3                 1                 0  ...             0             0   \n",
       "4                 0                 1  ...             0             0   \n",
       "\n",
       "   Dependents_3+  Education_Graduate  Education_Not Graduate  \\\n",
       "0              0                   1                       0   \n",
       "1              0                   1                       0   \n",
       "2              0                   1                       0   \n",
       "3              0                   0                       1   \n",
       "4              0                   1                       0   \n",
       "\n",
       "   Self_Employed_No  Self_Employed_Yes  Property_Area_Rural  \\\n",
       "0                 1                  0                    0   \n",
       "1                 1                  0                    1   \n",
       "2                 0                  1                    0   \n",
       "3                 1                  0                    0   \n",
       "4                 1                  0                    0   \n",
       "\n",
       "   Property_Area_Semiurban  Property_Area_Urban  \n",
       "0                        0                    1  \n",
       "1                        0                    0  \n",
       "2                        0                    1  \n",
       "3                        0                    1  \n",
       "4                        0                    1  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4342ef0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Y\n",
       "1    N\n",
       "2    Y\n",
       "3    Y\n",
       "4    Y\n",
       "Name: Loan_Status, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "865b0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26a362",
   "metadata": {},
   "source": [
    "#### (a) LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a211b76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\W I N D O W S\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ccdbe24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cv=model.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e736991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7398373983739838\n",
      "[[21 22]\n",
      " [10 70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(accuracy_score(y_cv,pred_cv))\n",
    "matrix=confusion_matrix(y_cv,pred_cv)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed893e",
   "metadata": {},
   "source": [
    "#### (b) DECISION TREE ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "199c28c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt=tree.DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e69a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cv1=dt.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a53bfd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7560975609756098\n",
      "[[19 24]\n",
      " [ 6 74]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cv,pred_cv1))\n",
    "matrix1=confusion_matrix(y_cv,pred_cv1)\n",
    "print(matrix1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0e819",
   "metadata": {},
   "source": [
    "#### (c) RANDOM FOREST ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f02799b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbb9ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cv2=rf.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66841ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7560975609756098\n",
      "[[17 26]\n",
      " [ 4 76]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cv,pred_cv2))\n",
    "matrix2=confusion_matrix(y_cv,pred_cv2)\n",
    "print(matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f66603",
   "metadata": {},
   "source": [
    "#### (d) SUPPORT VECTOR MACHINE (SVM) ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f6fa47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model=svm.SVC()\n",
    "svm_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6714e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cv3=svm_model.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c13ba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6504065040650406\n",
      "[[ 0 43]\n",
      " [ 0 80]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cv,pred_cv3))\n",
    "matrix3=confusion_matrix(y_cv,pred_cv3)\n",
    "print(matrix3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf277a3",
   "metadata": {},
   "source": [
    "#### (e) NAIVE BAYES ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07c73786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4c01241",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cv4=nb.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62911288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317073170731707\n",
      "[[18 25]\n",
      " [ 8 72]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cv,pred_cv4))\n",
    "matrix4=confusion_matrix(y_cv,pred_cv4)\n",
    "print(matrix4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db939d8",
   "metadata": {},
   "source": [
    "#### (f) K-NEAREST NEIGHBOR(kNN) ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d4640f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNN=KNeighborsClassifier()\n",
    "kNN.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3caffce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cv5=kNN.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7d13992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6504065040650406\n",
      "[[ 8 35]\n",
      " [ 8 72]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_cv,pred_cv5))\n",
    "matrix5=confusion_matrix(y_cv,pred_cv5)\n",
    "print(matrix5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c22502",
   "metadata": {},
   "source": [
    "#### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3dc800a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.7398373983739838\n",
      "Decision Tree: 0.7560975609756098\n",
      "Random Forest: 0.7560975609756098\n",
      "SVM: 0.6504065040650406\n",
      "Naive Bayes: 0.7317073170731707\n",
      "KNN: 0.6504065040650406\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\", accuracy_score(y_cv,pred_cv))\n",
    "print(\"Decision Tree:\", accuracy_score(y_cv,pred_cv1))\n",
    "print(\"Random Forest:\", accuracy_score(y_cv,pred_cv2))\n",
    "print(\"SVM:\", accuracy_score(y_cv,pred_cv3))\n",
    "print(\"Naive Bayes:\", accuracy_score(y_cv,pred_cv4))\n",
    "print(\"KNN:\", accuracy_score(y_cv,pred_cv5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f88fcf",
   "metadata": {},
   "source": [
    "#### Exporting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write test results in csv file\n",
    "\n",
    "predictions=pd.DataFrame(pred_cv2, columns=['predictions']).to_csv('H8_NB_Credit_Predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
